{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import regularizers, layers\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from time import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/creditCardActivity/creditcard.csv', engine='pyarrow')\n",
    "raw_data = data.values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate normal transactions from fraudulent transactions\n",
    "normal_data = data[data['Class'] == 0]\n",
    "normal_data_sample = normal_data.sample(4000)\n",
    "fraud_data = data[data['Class'] == 1]\n",
    "\n",
    "reduced_set = pd.concat([normal_data_sample, fraud_data]).reset_index(drop=True)\n",
    "\n",
    "# Splitting the dataset into X and y features\n",
    "y = reduced_set['Class']\n",
    "X = reduced_set.drop('Class', axis=1)\n",
    "X = X.drop('Time', axis=1)\n",
    "\n",
    "X.to_json('test_data.json', orient='records')\n",
    "\n",
    "\n",
    "y = data['Class']\n",
    "X = data.drop('Class', axis=1)\n",
    "X = X.drop('Time', axis=1)\n",
    "\n",
    "test_normal = normal_data.drop('Class', axis=1)\n",
    "test_fraud = fraud_data.drop('Class', axis=1)\n",
    "test_normal = test_normal.drop('Time', axis=1)\n",
    "test_fraud = test_fraud.drop('Time', axis=1)\n",
    "\n",
    "# # Normalize and scale the data\n",
    "# scaler = RobustScaler().fit_transform(X)\n",
    "\n",
    "# # Scaled data\n",
    "# X_scaled_normal = scaler[y == 0]\n",
    "# X_scaled_fraud = scaler[y == 1]\n",
    "\n",
    "print(f\"Reduced dataset shape : {reduced_set.shape}\")\n",
    "print(f\"Shape of Features : {X.shape} and Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "def dimensionality_plot(X, y):\n",
    "    sns.set(style='whitegrid', palette='muted')\n",
    "    # Initializing TSNE object with 2 principal components\n",
    "    tsne = TSNE(n_components=2, random_state=42, init='random', learning_rate=200)\n",
    "    # Fitting the data\n",
    "    X_trans = tsne.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    \n",
    "    plt.scatter(X_trans[np.where(y == 0), 0], X_trans[np.where(y==0), 1], marker='o', color='green', linewidth=1, alpha=0.8, label='Normal')\n",
    "    plt.scatter(X_trans[np.where(y == 1), 0], X_trans[np.where(y==1), 1], marker='o', color='red', linewidth=1, alpha=0.8, label='Fraud')\n",
    "    \n",
    "    plt.legend(loc = 'best')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality_plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the input data : {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relative 'Time' to hour of day\n",
    "data['Time'] = data['Time'].apply(lambda t: (t / 3600) % 24)\n",
    "\n",
    "# Scale Time and Amount\n",
    "# data['Time'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "data = data.drop(['Time'], axis=1)\n",
    "# data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "train_x, test_x = train_test_split(data, test_size=0.2, random_state=736)\n",
    "train_x = train_x[train_x['Class'] == 0]    # train only on normal transactions data\n",
    "train_x = train_x.drop(['Class'], axis=1)   # drop the class column\n",
    "\n",
    "test_x_normal = test_x[test_x['Class'] == 0].sample(5000)\n",
    "test_x_normal = test_x_normal.drop(['Class'], axis=1).values\n",
    "test_x_fraud = test_x[test_x['Class'] == 1]\n",
    "test_x_fraud = test_x_fraud.drop(['Class'], axis=1).values\n",
    "\n",
    "test_normal_sample = normal_data_sample.drop(['Class'], axis=1) \n",
    "test_fraud_sample = fraud_data.drop(['Class'], axis=1)\n",
    "\n",
    "test_y = test_x['Class']                    # save the class column for the test set\n",
    "test_x = test_x.drop(['Class'], axis=1)     # drop the class column\n",
    "\n",
    "test = test_x.sample(1)\n",
    "\n",
    "train_x = train_x.values                    # transform to ndarray\n",
    "test_x = test_x.values                      # transform to ndarray\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"epochs\": 150,\n",
    "    \"batch_size\": 32,\n",
    "    \"threshold\": 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model :) \n",
    "class FraudDetector(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FraudDetector, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(18, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(10, activation='relu'),\n",
    "            layers.Dense( 6, activation='tanh', activity_regularizer=regularizers.l1(1e-7))]        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(10, activation='relu'),\n",
    "            layers.Dense(18, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(30, activation='relu')]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model :) \n",
    "class FraudDetector_2(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FraudDetector_2, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(29, activation='relu', input_shape=(29, )),\n",
    "            layers.Dense(14, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense( 7, activation='tanh', activity_regularizer=regularizers.l1(1e-7))]    \n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(14, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(29, activation='relu')]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, encoded_x):\n",
    "        return self.decoder(excoded_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model :) \n",
    "class FraudDetector_3(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FraudDetector_3, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(30, activation='relu', input_shape=(30, )),\n",
    "            layers.Dense(14, activation='relu'),\n",
    "            layers.Dense( 7, activation='relu')]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(14, activation='relu'),\n",
    "            layers.Dense(30, activation='relu')]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = FraudDetector_2()\n",
    "\n",
    "# Compule the model\n",
    "autoencoder.compile(optimizer='adam', metrics = ['accuracy'], loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = autoencoder.fit(x=train_x, y=train_x, batch_size=hyperparams['batch_size'], epochs=hyperparams['epochs'], shuffle=True, validation_data=(test_x, test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_points = autoencoder.predict(test_normal_sample)\n",
    "# fraud_points = autoencoder.predict(test_fraud_sample)\n",
    "\n",
    "# normal_points = autoencoder.predict(test_x_normal)\n",
    "# fraud_points = autoencoder.predict(test_x_fraud)\n",
    "\n",
    "normal_points = autoencoder.predict(test_normal)\n",
    "fraud_points = autoencoder.predict(test_fraud)\n",
    "\n",
    "encoded_X = np.append(normal_points, fraud_points, axis=0)\n",
    "y_normal = np.zeros(normal_points.shape[0])\n",
    "y_fraud = np.ones(fraud_points.shape[0])\n",
    "encoded_y = np.append(y_normal, y_fraud, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensionality_plot(encoded_X, encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_points = autoencoder.predict(test_normal_sample)\n",
    "fraud_points = autoencoder.predict(test_fraud_sample)\n",
    "\n",
    "mse = np.mean(np.square(test_fraud_sample - fraud_points), axis = 1)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test)\n",
    "mse = np.mean(np.power(test_x - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': test_y})\n",
    "error_df.describe()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error without fraud\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class']== 0) & (error_df['reconstruction_error'] < 10)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error with fraud\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fraud_error_df = error_df[error_df['true_class'] == 1]\n",
    "_ = ax.hist(fraud_error_df.reconstruction_error.values, bins=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.001, 1])\n",
    "plt.ylim([0, 1.001])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction analysis\n",
    "\n",
    "error_threshold = 2.9\n",
    "\n",
    "groups = error_df.groupby('true_class')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.reconstruction_error, marker='o', color=\"r\" if name == 1 else \"g\", ms=3.5, linestyle='',\n",
    "            label=\"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(error_threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"b\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for different classes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "y_pred = [1 if e > error_threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=[\"Normal\", \"Fraud\"], yticklabels=[\"Normal\", \"Fraud\"], annot=True, fmt=\"d\");\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = int(time())\n",
    "filepath = f'../models/fraud_detector/{ts}'\n",
    "autoencoder.save(filepath=filepath, save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
