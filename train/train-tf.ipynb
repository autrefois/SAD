{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "\n",
    "from keras import regularizers, layers\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./dataset/creditCardActivity/creditcard.csv', engine='pyarrow')\n",
    "raw_data = data.values\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate normal transactions from fraudulent transactions\n",
    "normal_data = data[data['Class'] == 0]\n",
    "normal_data_sample = normal_data.sample(4000)\n",
    "fraud_data = data[data['Class'] == 1]\n",
    "\n",
    "# reduced_set = pd.concat([normal_data_sample, fraud_data]).reset_index(drop=True)\n",
    "reduced_set = pd.concat([normal_data_sample, fraud_data.sample(frac=1)]).reset_index(drop=True)\n",
    "\n",
    "# Splitting the dataset into X and y features\n",
    "y_reduced = reduced_set['Class']\n",
    "X_reduced = reduced_set.drop('Class', axis=1)\n",
    "X_reduced = X_reduced.drop('Time', axis=1)\n",
    "\n",
    "# X.to_json('test_data.json', orient='records')\n",
    "\n",
    "y = data['Class']\n",
    "X = data.drop('Class', axis=1)\n",
    "X = X.drop('Time', axis=1)\n",
    "\n",
    "test_normal = normal_data.drop('Class', axis=1)\n",
    "test_fraud = fraud_data.drop('Class', axis=1)\n",
    "test_normal = test_normal.drop('Time', axis=1)\n",
    "test_fraud = test_fraud.drop('Time', axis=1)\n",
    "\n",
    "print(f\"Reduced dataset shape : {reduced_set.shape}\")\n",
    "print(f\"Shape of Features : {X.shape} and Target: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the data\n",
    "def tsne_plot(X, y):\n",
    "    sns.set(style='whitegrid', palette='muted')\n",
    "    # Initializing TSNE object with 2 principal components\n",
    "    tsne = TSNE(n_components=2, random_state=42, init='random', learning_rate=200)\n",
    "    # Fitting the data\n",
    "    X_trans = tsne.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    plt.scatter(X_trans[np.where(y == 0), 0], X_trans[np.where(y == 0), 1], marker='o', color='blue', linewidth=1, alpha=0.8, label='Normal')\n",
    "    plt.scatter(X_trans[np.where(y == 1), 0], X_trans[np.where(y == 1), 1], marker='o', color='orange', linewidth=1, alpha=0.8, label='Fraud')\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of the input data : {X.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert relative 'Time' to hour of day\n",
    "# data['Time'] = data['Time'].apply(lambda t: (t / 3600) % 24)\n",
    "\n",
    "# Scale Time and Amount\n",
    "# data['Time'] = StandardScaler().fit_transform(data['Time'].values.reshape(-1, 1))\n",
    "# data['Amount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1, 1))\n",
    "\n",
    "# Better accuracy\n",
    "data = data.drop(['Time'], axis=1)\n",
    "\n",
    "train_x, test_x = train_test_split(data, test_size=0.2, random_state=736)\n",
    "train_x = train_x[train_x['Class'] == 0]    # train only on normal transactions data\n",
    "train_x = train_x.drop(['Class'], axis=1)   # drop the class column\n",
    "\n",
    "test_x_normal = test_x[test_x['Class'] == 0].sample(5000)\n",
    "test_x_normal = test_x_normal.drop(['Class'], axis=1).values\n",
    "test_x_fraud = test_x[test_x['Class'] == 1]\n",
    "test_x_fraud = test_x_fraud.drop(['Class'], axis=1).values\n",
    "\n",
    "test_normal_sample = normal_data_sample.drop(['Class'], axis=1)\n",
    "test_fraud_sample = fraud_data.drop(['Class'], axis=1)\n",
    "# test_normal_sample = normal_data_sample.drop(['Time'], axis=1)\n",
    "# test_fraud_sample = fraud_data.drop(['Time'], axis=1)\n",
    "\n",
    "test_y = test_x['Class']                    # save the class column for the test set\n",
    "test_x = test_x.drop(['Class'], axis=1)     # drop the class column\n",
    "\n",
    "test = test_x.sample(1)\n",
    "\n",
    "train_x = train_x.values                    # transform to ndarray\n",
    "test_x = test_x.values                      # transform to ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"epochs\": 2,\n",
    "    \"batch_size\": 32,\n",
    "    \"threshold\": 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model :)\n",
    "class deprecated_FraudDetector(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(deprecated_FraudDetector, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(18, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(10, activation='relu'),\n",
    "            layers.Dense(6, activation='tanh', activity_regularizer=regularizers.l1(1e-7))])\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(10, activation='relu'),\n",
    "            layers.Dense(18, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(30, activation='relu')]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model :)\n",
    "class FraudDetector(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(FraudDetector, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(29, activation='relu', input_shape=(29, )),\n",
    "            layers.Dense(14, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(7, activation='tanh', activity_regularizer=regularizers.l1(1e-7))]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(14, activation='tanh', activity_regularizer=regularizers.l1(1e-7)),\n",
    "            layers.Dense(29, activation='relu')]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "    def decode(self, encoded_x):\n",
    "        return self.decoder(encoded_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model :)\n",
    "class deprecated_SimpleDetector(Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(deprecated_SimpleDetector, self).__init__()\n",
    "\n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            layers.Dense(30, activation='relu', input_shape=(30, )),\n",
    "            layers.Dense(14, activation='relu'),\n",
    "            layers.Dense(7, activation='relu')]\n",
    "        )\n",
    "\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            layers.Dense(14, activation='relu'),\n",
    "            layers.Dense(30, activation='relu')]\n",
    "        )\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 14:43:22.538058: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7108/7108 [==============================] - ETA: 0s - loss: 2196.6079 - accuracy: 0.8823"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-27 14:44:11.423429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7108/7108 [==============================] - 56s 8ms/step - loss: 2196.6079 - accuracy: 0.8823 - val_loss: 2028.5396 - val_accuracy: 0.8886\n",
      "Epoch 2/2\n",
      "4786/7108 [===================>..........] - ETA: 16s - loss: 1927.2899 - accuracy: 0.8927"
     ]
    }
   ],
   "source": [
    "autoencoder = FraudDetector()\n",
    "\n",
    "# Compule the model\n",
    "autoencoder.compile(optimizer='adam', metrics=['accuracy'], loss='mse')\n",
    "\n",
    "# Train the model\n",
    "history = autoencoder.fit(x=train_x, y=train_x, batch_size=hyperparams['batch_size'], epochs=hyperparams['epochs'], shuffle=True, validation_data=(test_x, test_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fraud_detector_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " sequential_2 (Sequential)   (None, 7)                 1395      \n",
      "                                                                 \n",
      " sequential_3 (Sequential)   (None, 29)                547       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,942\n",
      "Trainable params: 1,942\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(autoencoder.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal_points = autoencoder.predict(test_normal_sample)\n",
    "# fraud_points = autoencoder.predict(test_fraud_sample)\n",
    "\n",
    "# normal_points = autoencoder.predict(test_x_normal)\n",
    "# fraud_points = autoencoder.predict(test_x_fraud)\n",
    "\n",
    "normal_points = autoencoder.predict(test_normal)\n",
    "fraud_points = autoencoder.predict(test_fraud)\n",
    "\n",
    "encoded_X = np.append(normal_points, fraud_points, axis=0)\n",
    "y_normal = np.zeros(normal_points.shape[0])\n",
    "y_fraud = np.ones(fraud_points.shape[0])\n",
    "encoded_y = np.append(y_normal, y_fraud, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_plot(encoded_X, encoded_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_points = autoencoder.predict(test_normal_sample)\n",
    "fraud_points = autoencoder.predict(test_fraud_sample)\n",
    "\n",
    "mse = np.mean(np.square(test_fraud_sample - fraud_points), axis=1)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = autoencoder.predict(test)\n",
    "mse = np.mean(np.power(test_x - predictions, 2), axis=1)\n",
    "error_df = pd.DataFrame({'reconstruction_error': mse,\n",
    "                        'true_class': test_y})\n",
    "error_df.describe()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error without fraud\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "normal_error_df = error_df[(error_df['true_class'] == 0) & (error_df['reconstruction_error'] < 10)]\n",
    "_ = ax.hist(normal_error_df.reconstruction_error.values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction error with fraud\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "fraud_error_df = error_df[error_df['true_class'] == 1]\n",
    "_ = ax.hist(fraud_error_df.reconstruction_error.values, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
    "                             roc_curve, recall_score, classification_report, f1_score,\n",
    "                             precision_recall_fscore_support)\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, label='AUC = %0.4f' % roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([-0.001, 1])\n",
    "plt.ylim([0, 1.001])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error)\n",
    "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
    "plt.title('Recall vs Precision')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction analysis\n",
    "\n",
    "error_threshold = 2.9\n",
    "\n",
    "groups = error_df.groupby('true_class')\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "for name, group in groups:\n",
    "    ax.plot(group.index, group.reconstruction_error, marker='o', color=\"r\" if name == 1 else \"g\", ms=3.5, linestyle='',\n",
    "            label=\"Fraud\" if name == 1 else \"Normal\")\n",
    "ax.hlines(error_threshold, ax.get_xlim()[0], ax.get_xlim()[1], colors=\"b\", zorder=100, label='Threshold')\n",
    "ax.legend()\n",
    "plt.title(\"Reconstruction error for different classes\")\n",
    "plt.ylabel(\"Reconstruction error\")\n",
    "plt.xlabel(\"Data point index\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "y_pred = [1 if e > error_threshold else 0 for e in error_df.reconstruction_error.values]\n",
    "conf_matrix = confusion_matrix(error_df.true_class, y_pred)\n",
    "plt.figure(figsize=(12, 12))\n",
    "sns.heatmap(conf_matrix, xticklabels=[\"Normal\", \"Fraud\"], yticklabels=[\"Normal\", \"Fraud\"], annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = int(time())\n",
    "filepath = f'../models/fraud_detector/{ts}'\n",
    "autoencoder.save(filepath=filepath, save_format='tf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
